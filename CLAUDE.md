# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Commands

### Proxy Server
- **Start WSL Proxy Server**: `./start-proxy.sh` (runs on port 8081)
- **Manual Start**: `cd proxy && npm install && node server.js`

### Electron Apps
- **Main Chat App**: `npm install && npm start` (or `npm run dev`)

### Pipeline System
- **Start Pipeline System**: `./start-pipeline-system.sh` (launches proxy + file server + web UI on http://localhost:3003)
- **Start Pipeline Monitor**: `./start-monitor.sh` (launches monitoring interface on http://localhost:3004/pipeline-monitor.html)
- **Start Infographic Viewer**: `./start-infographic-viewer.sh` (launches rich media viewer on http://localhost:3005/infographic-viewer.html)
- **Start Game Dev Studio**: `./start-game-dev-studio.sh` (launches AI development partner on http://localhost:3006/game-dev-studio.html)

### MCP Server Components
- **Browser Automation Server**: `cd mcp-servers/browser-automation && npm install && npm start`
- **Browser Automation Dev**: `cd mcp-servers/browser-automation && npm run dev`

## Architecture

This is a Claude Proxy System with a three-tier architecture:

```
Windows Electron App → WebSocket (port 8081) → WSL Proxy Server → Claude Code Processes
```

### Core Components

1. **Main Electron App** (`src/`): Windows GUI chat interface
   - Entry point: `src/main.js`
   - Renderer: `src/renderer.js`, `src/index.html`
   - WebSocket client connecting to proxy on port 8081
   - Uses secure IPC with `contextIsolation: true` and `nodeIntegration: false`
   - Includes directory selection for changing Claude working directory

2. **WSL Proxy Server** (`proxy/server.js`): Node.js WebSocket server
   - Manages WebSocket connections from Electron clients
   - Spawns Claude Code processes directly
   - Tracks conversation history per client
   - Manages working directories (converts Windows paths to WSL paths)
   - Logs to `proxy/proxy.log`
   - Claude instances execute in `output/` directory (auto-created with permissions config)

3. **Pipeline Designer** (`src/pipeline-designer.js`, `src/pipeline-designer.html`): Visual pipeline editor
   - Drag-and-drop interface for building AI agent pipelines
   - Uses templates from `templates/*.json`
   - Configures agent workflows dynamically
   - Can be accessed standalone via `./start-pipeline-system.sh`

4. **Pipeline Monitor** (`pipeline-monitor.html`): Specialized monitoring interface
   - Chat interface with Claude Code CLI for system monitoring
   - Context-aware about project structure and log locations
   - Intelligently parses structured execution logs (proxy/pipelines/*_execution.json)
   - Quick commands for status, errors, execution history, health checks
   - Knows to check structured logs FIRST before reading proxy.log
   - Access via `./start-monitor.sh` on http://localhost:3004/pipeline-monitor.html

5. **Pipeline Infographic Viewer** (`infographic-viewer.html`): Real-time visual execution reports
   - Rich HTML infographics generated during pipeline runs
   - Visual timeline of all stages with agent outputs
   - Agent decisions, routing, and error tracking
   - Auto-refresh every 2 seconds for real-time updates
   - Support for images, code snippets, and structured data
   - Designed for reviewing development process and debugging
   - Generated by `InfographicGenerator` class in `proxy/infographic-generator.js`
   - Infographics stored in `proxy/pipeline-infographics/`
   - Access via `./start-infographic-viewer.sh` on http://localhost:3005/infographic-viewer.html

6. **Game Dev Studio** (`game-dev-studio.html`): AI development partner chat interface
   - Natural conversation with Claude Code CLI for game development
   - Automatically triggers pipeline execution when building features
   - Can modify its own interface based on user requests
   - Real-time pipeline progress tracking with visual updates
   - Directory targeting for working on any game project
   - Specialized context for game development workflows
   - Quick commands for common development tasks
   - Access via `./start-game-dev-studio.sh` on http://localhost:3006/game-dev-studio.html

7. **MCP Browser Automation** (`mcp-servers/browser-automation/`): Playwright-based browser automation
   - Provides web scraping and browser testing capabilities

8. **Web Interfaces**: Multiple access points
   - Main Electron app (`src/index.html`)
   - Web-based chat interface (`src/claude-app-web.html`)
   - Standalone pipeline designer (via `./start-pipeline-system.sh`)
   - Pipeline monitor (via `./start-monitor.sh`)
   - Pipeline infographic viewer (via `./start-infographic-viewer.sh`)
   - Game Dev Studio (via `./start-game-dev-studio.sh`)

### Key Technical Details

- **Proxy Communication**: WebSocket on port 8081, JSON message protocol with types: `user-message`, `directory-change`, `pipeline-config`, `get-templates`, `get-agents`, `pipeline-monitor-init`, `pipeline-monitor-query`, `game-dev-studio-init`, `game-dev-studio-query`, `pipeline-started`, `pipeline-update`, `pipeline-completed`, `infographic-ready`, etc.
- **HTTP API**: Port 8081 also serves HTTP endpoints: `/list-infographics` for querying available pipeline visualizations
- **Path Conversion**: Windows paths (C:\path) automatically converted to WSL paths (/mnt/c/path) in proxy
- **Process Management**: Proxy kills existing processes on port 8081 before starting
- **Conversation History**: Maintained per WebSocket client for context across requests
- **Pipeline Persistence**: Active pipelines saved to `proxy/pipelines/*.json`, templates in `templates/`, agents in `agents/`
- **Infographic Generation**: Real-time HTML reports generated in `proxy/pipeline-infographics/`, updated on every pipeline event
- **Claude Code Execution**: All Claude instances run in `output/` directory with pre-configured permissions (Write, Edit, Bash, Read, Glob, Grep)

## Agent System

The system uses 38+ JSON-defined agents organized by category:

### Core Workflow Agents
- **task_planner**: Creates execution plans with UNDERSTANDING, APPROACH, STEPS, TEST_CONSIDERATIONS, EVIDENCE, CONFIDENCE
- **task_executor**: Executes the plan with tool usage
- **proof_validator**: Validates execution results
- **discerning_expert**: Reviews plans before execution

### Specialized Agent Categories
- **Game Design**: combat_designer, economy_designer, geography_designer, lore_architect, culture_architect
- **System Design**: system_designer, systems_integrator, api_designer, data_modeler, code_generator
- **Validation**: design_validator, technical_validator, gameplay_validator, ecology_validator, narrative_validator
- **Analysis**: balance_analyzer, balance_auditor, engagement_scorer, emergence_detector, player_experience_simulator
- **Testing & Validation**:
  - **test_planner**: Writes actual test script files (not just plans)
  - **feature_validator**: Executes pre-written test scripts for feature validation
  - **game_runner**: Executes bug reproduction scripts
  - **qa_tester**: Final test quality checks
  - **final_integrator**: Integration testing
- **Test Management**: test_librarian (collects, validates, and commits tests to library)
- **Domain Experts**: world_historian, sociologist_reviewer, market_simulator, resource_designer, progression_designer

### Template System
Pre-configured pipeline workflows in `templates/`:
- `claude-plus-v1.json`: Basic Claude Plus workflow
- `bug-fix-v1.json`: Comprehensive bug fix pipeline with test finalization
- `feature-development-v1.json`: Test-first feature development with test finalization
- `game-design-v1.json`: Game development pipeline
- `living-game-world-v1.json`: Complex world simulation pipeline
- `thesis-generator-v1.json`: Academic thesis generation workflow

## ChromeManager - Browser Testing Infrastructure

**Location**: `/mnt/c/github/superstarships/lib/ChromeManager.js`

ChromeManager is a JavaScript class that handles all Chrome lifecycle management for automated testing. It provides a simple abstraction over complex Chrome management, eliminating 200+ lines of boilerplate from every test script.

### What ChromeManager Handles Automatically

- ✅ Chrome launch with correct WSL path (`/mnt/c/Program Files/Google/Chrome/Application/chrome.exe`)
- ✅ All cache-disable flags (`--disable-http-cache`, `--disable-cache`, `--disk-cache-size=1`, `--aggressive-cache-discard`)
- ✅ Console log capture via `--enable-logging` flag (NO CDP, NO Puppeteer)
- ✅ Parses `chrome_debug.log` automatically with regex patterns for errors/exceptions
- ✅ PID tracking via port lookup (`netstat.exe`)
- ✅ Process cleanup (kills by PID and port)
- ✅ Profile directory management with Windows path format
- ✅ Auto-detection of log file location (searches temp directories)
- ✅ Evidence collection with structured console data

### Basic Usage

```javascript
const ChromeManager = require('./lib/ChromeManager');

const chrome = new ChromeManager();

// Launch Chrome
await chrome.launch({ url: '/index.html', testMode: true });
await chrome.waitForReady(10);

// ... run tests ...

// Get console logs
const summary = chrome.getConsoleSummary();
console.log(`Errors: ${summary.consoleErrorCount}`);
console.log(`Exceptions: ${summary.consoleExceptionCount}`);

// Cleanup
await chrome.kill();
```

### Agent Integration Pattern

Agents that create test scripts should use the ChromeManager template pattern:

1. **reproduction_creator**: Creates bug reproduction scripts with `defineScenario()` function
2. **test_planner**: Creates feature test scripts with `defineScenario()` function
3. **game_runner**: Executes reproduction scripts (ChromeManager built-in)
4. **feature_validator**: Executes feature test scripts (ChromeManager built-in)

### Example defineScenario() Pattern

Agents only write the test logic (10-20 lines):

```javascript
function defineScenario() {
  return [
    {
      command: 'setThrottle',
      params: {value: 100},
      verify: (r) => r.throttle === 100,
      desc: 'Set full throttle'
    },
    {
      command: 'wait',
      params: {duration: 5000},
      verify: () => true,
      desc: 'Wait 5 seconds'
    },
    {
      command: 'getShipState',
      params: {},
      verify: (r) => {
        const speed = Math.sqrt(r.velocity.x**2 + r.velocity.y**2 + r.velocity.z**2);
        return speed === 0;  // Bug reproduced if ship not moving
      },
      desc: 'Verify bug: ship not moving'
    }
  ];
}
```

### Why Not CDP or Puppeteer?

ChromeManager uses Chrome's built-in `--enable-logging` flag which writes all console output to `chrome_debug.log` automatically. This approach:

- ✅ **No network dependencies**: Doesn't require CDP endpoint or Puppeteer connection
- ✅ **No WSL-Windows networking**: Avoids port forwarding issues between WSL and Windows
- ✅ **Simple and reliable**: Just spawn Chrome and read a log file
- ✅ **Complete console data**: Captures all console.log, errors, and exceptions
- ✅ **No timing issues**: Log file persists after Chrome closes

### Console Log Format

ChromeManager parses `chrome_debug.log` into structured data:

```json
{
  "logFile": "/mnt/c/Users/user/AppData/Local/Temp/ChromeTest_1763400000000/chrome_debug.log",
  "windowsPath": "C:\\Users\\user\\AppData\\Local\\Temp\\ChromeTest_1763400000000\\chrome_debug.log",
  "totalLines": 4823,
  "consoleLogs": [
    {
      "type": "CONSOLE.LOG",
      "level": "1",
      "message": "Game initialized",
      "source": "http://localhost:8080/js/main.js",
      "line": "42"
    },
    {
      "type": "CONSOLE.ERROR",
      "message": "TypeError: Cannot read property 'position' of undefined"
    },
    {
      "type": "EXCEPTION",
      "message": "Uncaught ReferenceError: foo is not defined"
    }
  ],
  "consoleErrorCount": 5,
  "consoleExceptionCount": 2
}
```

### Key Methods

- `launch(options)` - Launch Chrome with test URL
- `waitForReady(seconds)` - Wait for Chrome to initialize
- `kill()` - Kill Chrome process and cleanup
- `killAllChrome()` - Nuclear option - kill ALL Chrome processes
- `parseConsoleLogs()` - Parse chrome_debug.log into structured data
- `getConsoleSummary()` - Print and return console log summary
- `getChromeLogPath()` - Get WSL path to chrome_debug.log
- `getChromeLogPathWindows()` - Get Windows path to chrome_debug.log

### Debugging and Logs

**IMPORTANT**: When debugging pipeline failures or execution issues, ALWAYS check the structured execution logs FIRST before reading the plain text proxy.log file.

#### Primary Debug Sources (check in this order):

1. **Structured Pipeline Execution Logs** (PREFERRED): `proxy/pipelines/<pipeline-id>_execution.json`
   - Example: `proxy/pipelines/claude-plus-v1_execution.json`
   - **USE THIS FIRST** - Contains structured JSON events with timestamps, errors, stack traces, and full execution history
   - Each event has: `timestamp`, `eventType`, `stageId`, `stageName`, `agent`, and error details
   - Events include: `pipeline_initialized`, `stage_started`, `stage_completed`, `stage_error`, `stage_routed`, `pipeline_completed`
   - Error events contain: `error` (message), `stack` (full stack trace)
   - Read the end of the file with `tail -n 100` to see recent executions
   - Each pipeline execution appends to this file with all events

2. **Pipeline State Files**: `proxy/pipeline-states/pipeline_<timestamp>.json` and `proxy/pipeline-states/current.json`
   - Contains current pipeline state: stages, connections, workingDir, completedStages, status, results
   - Use for understanding pipeline configuration and current execution state
   - `current.json` always points to the most recent pipeline

3. **Plain Text Proxy Log**: `proxy/proxy.log` (LAST RESORT)
   - Contains unstructured console output from proxy server
   - Very large file (30k+ lines), difficult to parse
   - Use only if structured logs don't exist
   - Search with grep for specific error patterns: `grep "ERROR\|ENOENT\|failed" proxy/proxy.log`

#### Common Error Patterns in Execution Logs:

- **`spawn claude ENOENT`**: Claude Code executable not found in PATH
  - Check if `claude` command is available: `which claude`
  - Fix by using `npx @anthropic-ai/claude-code` or full path in spawn calls

- **`stage_error` events**: Agent execution failed
  - Check `error` and `stack` fields in the event
  - Review `stageId` and `agent` to identify which stage failed

- **Missing `stage_completed` after `stage_started`**: Agent hung or crashed
  - Check for timeout issues or infinite loops

#### Debug Workflow Example:
```bash
# Step 1: Check structured execution log (ALWAYS START HERE)
tail -n 100 /mnt/c/github/claudeplus/proxy/pipelines/claude-plus-v1_execution.json

# Step 2: Check current pipeline state
cat /mnt/c/github/claudeplus/proxy/pipeline-states/current.json

# Step 3: Only if needed, search plain text log
grep "ERROR\|spawn.*ENOENT" /mnt/c/github/claudeplus/proxy/proxy.log | tail -n 50
```

#### Additional Debug Resources:
- **Claude Code Output**: `output/` directory with permissions pre-configured
- **Agent Definitions**: All agents stored in `agents/` directory as JSON files

## Test Library System

The system maintains a centralized test library that automatically collects tests from completed bug-fix and feature-development pipelines.

### Test Library Structure

```
test-library/
├── test-metadata.json          # Central metadata and statistics
└── categories/
    ├── bug-fixes/              # Tests from bug fix pipelines
    ├── features/               # Tests from feature development pipelines
    ├── integration/            # Integration tests
    └── regression/             # Regression tests
```

### How It Works

The test library system is integrated directly into pipeline templates as dedicated stages:

1. **Test Finalization Stage** (qa_tester agent):
   - Ensures tests are properly named and documented
   - Adds descriptive comments explaining what the test does
   - Prepares tests for collection
   - Runs after fix validation or feature completion

2. **Test Collection Stage** (test_librarian agent):
   - Scans working directory for test files (test-*.sh, test-*.bat, *.test.js, *.spec.js, reproduction-*.sh, validation-*.sh, etc.)
   - Validates each test file:
     - File exists and is readable
     - File is not empty
     - Has proper permissions (executable for .sh/.bat files)
     - Metadata file exists and is valid JSON
     - Contains meaningful code (not just comments)
   - Copies valid tests to `test-library/categories/` (bug-fixes, features, integration, regression)
   - Creates metadata sidecar files (.metadata.json) with pipeline context
   - Updates central metadata file with statistics
   - Commits test library changes to git with descriptive commit message
   - Returns decision: `tests_collected_and_committed`, `no_tests_found`, or `all_tests_invalid`

3. **Pipeline Integration**:
   - Both `bug-fix-v1` and `feature-development-v1` pipelines include these stages
   - Test collection happens as a normal pipeline stage (not proxy automation)
   - Agent has full context about pipeline, working directory, and test files
   - Git commit is created by the agent, not the proxy

4. **Metadata Tracking**: Each test includes:
   - Original file path and source directory
   - Pipeline ID, name, and type that created it
   - Timestamp when added to library
   - Auto-generated tags (bug-fix, feature, shell, javascript, reproduction, validation, etc.)
   - Extracted description from test file comments
   - Validation results (file size, code lines, permissions)

### Using the Test Library

**Query tests by category:**
```javascript
const TestLibraryManager = require('./proxy/test-library-manager');
const testLibrary = new TestLibraryManager();

// Get all bug fix tests
const bugFixTests = testLibrary.queryTests({ category: 'bug-fixes' });

// Get tests by pipeline
const pipelineTests = testLibrary.queryTests({ pipelineId: 'bug-fix-v1' });

// Get tests by tags
const reproductionTests = testLibrary.queryTests({ tags: ['reproduction'] });

// Get recent tests (last 7 days)
const recentTests = testLibrary.queryTests({
  since: new Date(Date.now() - 7 * 24 * 60 * 60 * 1000)
});
```

**View statistics:**
```javascript
const stats = testLibrary.getStatistics();
console.log(stats);
// {
//   totalTests: 45,
//   bugFixTests: 22,
//   featureTests: 18,
//   integrationTests: 3,
//   regressionTests: 2
// }
```

### Test File Naming Conventions

To ensure tests are collected properly, name test files with these patterns:
- `test-*.sh` or `test-*.bat` - General test scripts
- `reproduction-*.sh` or `reproduction-*.bat` - Bug reproduction scripts
- `validation-*.sh` or `validation-*.bat` - Fix validation scripts
- `*.test.js` or `*.spec.js` - JavaScript test files

### Pipeline Stages

**Bug Fix Pipeline:**
```
bug_analysis → create_reproduction → run_reproduction → verify_bug →
root_cause → implement_fix → run_validation → validate_fix →
finalize_tests → collect_tests_to_library
```

**Feature Development Pipeline:**
```
define_feature → plan_tests (writes test script) → plan_implementation →
implement_feature → run_tests (executes test script) → observe_behavior →
validate_expectations → finalize_tests → collect_tests_to_library
```

Key differences in test handling:
- **test_planner**: Uses Write tool to create `test_[feature].js` file
- **feature_validator**: Finds and executes the pre-written test script
- **test_librarian**: Collects test script to library and commits

The `collect_tests_to_library` stage:
- Uses the `test_librarian` agent
- Automatically scans, validates, and collects tests
- Creates git commit with test library changes
- Returns decision based on outcome

### Benefits

1. **Regression Prevention**: All bug reproduction tests are preserved for future regression testing
2. **Feature Validation**: Feature tests document expected behavior and can verify future changes
3. **Knowledge Base**: Tests serve as executable documentation of system behavior
4. **Automation Ready**: Tests are immediately runnable for CI/CD integration
5. **Traceable**: Every test links back to the pipeline and issue that created it
6. **Version Controlled**: All tests are committed to git with clear provenance
7. **Quality Assured**: Automatic validation ensures tests are well-formed and executable
8. **Pipeline-Driven**: Test collection is part of the workflow, not hidden automation

## important-instruction-reminders
Do what has been asked; nothing more, nothing less.
NEVER create files unless they're absolutely necessary for achieving your goal.
ALWAYS prefer editing an existing file to creating a new one.
NEVER proactively create documentation files (*.md) or README files. Only create documentation files if explicitly requested by the User.